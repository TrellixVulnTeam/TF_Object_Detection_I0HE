{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"TF Object Detection.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r0QrQa_1aHRj"},"source":["Reference1: https://www.youtube.com/watch?v=IOI0o3Cxv9Q : https://github.com/nicknochnack/RealTimeObjectDetection \n","\n","Reference2: https://www.youtube.com/watch?v=XoMiveY_1Z4 (bike and car) : https://colab.research.google.com/drive/19ycUy5qIZKCO8tKy37f4zkUiHzgKs05I?usp=sharing\n","\n","Tutorial: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n","\n","Resources Used\n","- wget.download('https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py')\n","- Setup https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html"]},{"cell_type":"markdown","metadata":{"id":"wlBsvA4ae_Ln"},"source":["#0.0 Tensorflow Object Detection API Installation"]},{"cell_type":"code","metadata":{"id":"lJWlumJWfVZ2"},"source":["!pip install tensorflow-gpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o6RoECCZwNYE","executionInfo":{"status":"ok","timestamp":1628509891004,"user_tz":-480,"elapsed":402,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXsrxF_bfZbR"},"source":["!git clone https://github.com/tensorflow/models.git\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFskoyl6gi2D","executionInfo":{"status":"ok","timestamp":1628489848598,"user_tz":-480,"elapsed":362,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["!cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=."],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtww_K7XjyCh","executionInfo":{"status":"ok","timestamp":1628489853785,"user_tz":-480,"elapsed":380,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}},"outputId":"a6319610-cd55-4637-e7f8-3973e32b137c"},"source":["!git clone https://github.com/cocodataset/cocoapi.git"],"execution_count":37,"outputs":[{"output_type":"stream","text":["fatal: destination path 'cocoapi' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"atiZp9hzg1TB","executionInfo":{"status":"ok","timestamp":1628489113596,"user_tz":-480,"elapsed":6176,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}},"outputId":"3c14d823-4c1c-49bb-fd76-6aa60ccd0096"},"source":["!cd cocoapi/PythonAPI\n","!make"],"execution_count":28,"outputs":[{"output_type":"stream","text":["python setup.py build_ext --inplace\n","running build_ext\n","cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n","building 'pycocotools._mask' extension\n","creating build\n","creating build/common\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n","   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n","       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n","                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n","rm -rf build\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GVLMTc-kg_NJ","executionInfo":{"status":"ok","timestamp":1628489121394,"user_tz":-480,"elapsed":445,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["cp -r pycocotools /content/models/research"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k7_nhKKdf5H1","executionInfo":{"status":"ok","timestamp":1628489128414,"user_tz":-480,"elapsed":370,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}},"outputId":"ba0b64c4-8094-4bb1-c062-3ad753d4c7bf"},"source":["cd /content/models/research"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yMtkHgMohB7x","executionInfo":{"status":"ok","timestamp":1628489135112,"user_tz":-480,"elapsed":411,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["cp object_detection/packages/tf2/setup.py ."],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLTh-rfZhDxN","executionInfo":{"status":"ok","timestamp":1628489198255,"user_tz":-480,"elapsed":58381,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}},"outputId":"b2d8b8ca-c14f-4cdf-ad4e-7b763907da1c"},"source":["!python -m pip install .\n","!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Processing /content/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.31.0-cp37-cp37m-manylinux2010_x86_64.whl (9.7 MB)\n","\u001b[K     |████████████████████████████████| 9.7 MB 2.9 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 68.7 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.5.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 63.7 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.6 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n","\u001b[K     |████████████████████████████████| 679 kB 54.0 MB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 12.2 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.5.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 47.9 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 69.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n","\u001b[K     |████████████████████████████████| 37.1 MB 86 kB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 71.0 MB/s \n","\u001b[?25hRequirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.32.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.2.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.41.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.5.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.36.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.34.1)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.5.0)\n","Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.5.0.dev2021032900)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Collecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 45.1 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting future<1.0.0,>=0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 53.0 MB/s \n","\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 56.9 MB/s \n","\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Collecting avro-python3\n","  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Collecting portalocker==2.0.0\n","  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1660307 sha256=ae067cd0d48574214daf39f3fab653e72ae70ff9f734fb444e474f0a2aa785c2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ims_kobi/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=ba05b20b1eb3097b2ae9bfb94b54e32fbbbdea304b1c6bbad382445f094c7485\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=2dad659169656e29e47396fccc0e696d711f0ee2afc2a072642438afb1b3e1be\n","  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=c687da381c89c13f7f5f451284046b0bd66ffb36fe9909af2f412e4018cbf7da\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=eba9936748621a99af3628a083ab860886cdd19ca8d640618b64e0b4da8a5bfa\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=167578a7e3e31aed630ed608cc7dd8b6497febec057cfe228a07dc4a23a3c213\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n","Installing collected packages: requests, portalocker, future, dill, tf-slim, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.31.0 avro-python3-1.9.2.1 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-1.5.1 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.13.0 tensorflow-model-optimization-0.6.0 tf-models-official-2.5.1 tf-slim-1.1.0\n","2021-08-09 06:06:07.906456: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Running tests under Python 3.7.11: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2021-08-09 06:06:10.243350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n","2021-08-09 06:06:10.297281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-09 06:06:10.298121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-08-09 06:06:10.298170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","2021-08-09 06:06:10.424629: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n","2021-08-09 06:06:10.424732: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n","2021-08-09 06:06:10.554014: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n","2021-08-09 06:06:10.602963: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n","2021-08-09 06:06:10.603218: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2021-08-09 06:06:10.622627: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n","2021-08-09 06:06:10.628537: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n","2021-08-09 06:06:10.628583: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2021-08-09 06:06:10.628935: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-08-09 06:06:10.629081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-08-09 06:06:10.629106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n","W0809 06:06:10.855141 140568367847296 model_builder.py:1088] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.85s\n","I0809 06:06:11.089543 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.85s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.52s\n","I0809 06:06:11.614010 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.52s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n","I0809 06:06:11.859304 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n","I0809 06:06:12.082480 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","W0809 06:06:12.084665 140568367847296 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.8s\n","I0809 06:06:13.878393 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.8s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0809 06:06:13.879289 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","I0809 06:06:13.898783 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n","I0809 06:06:13.912203 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n","I0809 06:06:13.926306 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n","I0809 06:06:14.015895 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n","I0809 06:06:14.103088 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n","I0809 06:06:14.195135 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n","I0809 06:06:14.281991 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n","I0809 06:06:14.381979 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0809 06:06:14.408291 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0809 06:06:14.570124 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0809 06:06:14.570271 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n","I0809 06:06:14.570347 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n","I0809 06:06:14.572325 140568367847296 efficientnet_model.py:147] round_filter input=32 output=32\n","I0809 06:06:14.586053 140568367847296 efficientnet_model.py:147] round_filter input=32 output=32\n","I0809 06:06:14.586165 140568367847296 efficientnet_model.py:147] round_filter input=16 output=16\n","I0809 06:06:14.642220 140568367847296 efficientnet_model.py:147] round_filter input=16 output=16\n","I0809 06:06:14.642355 140568367847296 efficientnet_model.py:147] round_filter input=24 output=24\n","I0809 06:06:14.770583 140568367847296 efficientnet_model.py:147] round_filter input=24 output=24\n","I0809 06:06:14.770712 140568367847296 efficientnet_model.py:147] round_filter input=40 output=40\n","I0809 06:06:14.898109 140568367847296 efficientnet_model.py:147] round_filter input=40 output=40\n","I0809 06:06:14.898239 140568367847296 efficientnet_model.py:147] round_filter input=80 output=80\n","I0809 06:06:15.210595 140568367847296 efficientnet_model.py:147] round_filter input=80 output=80\n","I0809 06:06:15.210777 140568367847296 efficientnet_model.py:147] round_filter input=112 output=112\n","I0809 06:06:15.421631 140568367847296 efficientnet_model.py:147] round_filter input=112 output=112\n","I0809 06:06:15.421828 140568367847296 efficientnet_model.py:147] round_filter input=192 output=192\n","I0809 06:06:15.730169 140568367847296 efficientnet_model.py:147] round_filter input=192 output=192\n","I0809 06:06:15.730339 140568367847296 efficientnet_model.py:147] round_filter input=320 output=320\n","I0809 06:06:15.811481 140568367847296 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0809 06:06:15.859858 140568367847296 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0809 06:06:15.908965 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0809 06:06:15.909115 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n","I0809 06:06:15.909191 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n","I0809 06:06:15.910869 140568367847296 efficientnet_model.py:147] round_filter input=32 output=32\n","I0809 06:06:15.924274 140568367847296 efficientnet_model.py:147] round_filter input=32 output=32\n","I0809 06:06:15.924385 140568367847296 efficientnet_model.py:147] round_filter input=16 output=16\n","I0809 06:06:16.025293 140568367847296 efficientnet_model.py:147] round_filter input=16 output=16\n","I0809 06:06:16.025421 140568367847296 efficientnet_model.py:147] round_filter input=24 output=24\n","I0809 06:06:16.214767 140568367847296 efficientnet_model.py:147] round_filter input=24 output=24\n","I0809 06:06:16.214914 140568367847296 efficientnet_model.py:147] round_filter input=40 output=40\n","I0809 06:06:16.408687 140568367847296 efficientnet_model.py:147] round_filter input=40 output=40\n","I0809 06:06:16.408875 140568367847296 efficientnet_model.py:147] round_filter input=80 output=80\n","I0809 06:06:16.674794 140568367847296 efficientnet_model.py:147] round_filter input=80 output=80\n","I0809 06:06:16.675579 140568367847296 efficientnet_model.py:147] round_filter input=112 output=112\n","I0809 06:06:16.950237 140568367847296 efficientnet_model.py:147] round_filter input=112 output=112\n","I0809 06:06:16.950401 140568367847296 efficientnet_model.py:147] round_filter input=192 output=192\n","I0809 06:06:17.335500 140568367847296 efficientnet_model.py:147] round_filter input=192 output=192\n","I0809 06:06:17.335669 140568367847296 efficientnet_model.py:147] round_filter input=320 output=320\n","I0809 06:06:17.515169 140568367847296 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0809 06:06:17.558453 140568367847296 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0809 06:06:17.619296 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0809 06:06:17.619448 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n","I0809 06:06:17.619529 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n","I0809 06:06:17.621028 140568367847296 efficientnet_model.py:147] round_filter input=32 output=32\n","I0809 06:06:17.633606 140568367847296 efficientnet_model.py:147] round_filter input=32 output=32\n","I0809 06:06:17.633735 140568367847296 efficientnet_model.py:147] round_filter input=16 output=16\n","I0809 06:06:17.736507 140568367847296 efficientnet_model.py:147] round_filter input=16 output=16\n","I0809 06:06:17.736643 140568367847296 efficientnet_model.py:147] round_filter input=24 output=24\n","I0809 06:06:18.049135 140568367847296 efficientnet_model.py:147] round_filter input=24 output=24\n","I0809 06:06:18.049301 140568367847296 efficientnet_model.py:147] round_filter input=40 output=48\n","I0809 06:06:18.250118 140568367847296 efficientnet_model.py:147] round_filter input=40 output=48\n","I0809 06:06:18.250292 140568367847296 efficientnet_model.py:147] round_filter input=80 output=88\n","I0809 06:06:18.539904 140568367847296 efficientnet_model.py:147] round_filter input=80 output=88\n","I0809 06:06:18.540074 140568367847296 efficientnet_model.py:147] round_filter input=112 output=120\n","I0809 06:06:18.835715 140568367847296 efficientnet_model.py:147] round_filter input=112 output=120\n","I0809 06:06:18.835895 140568367847296 efficientnet_model.py:147] round_filter input=192 output=208\n","I0809 06:06:19.227502 140568367847296 efficientnet_model.py:147] round_filter input=192 output=208\n","I0809 06:06:19.227664 140568367847296 efficientnet_model.py:147] round_filter input=320 output=352\n","I0809 06:06:19.411387 140568367847296 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0809 06:06:19.461519 140568367847296 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0809 06:06:19.523313 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0809 06:06:19.523498 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n","I0809 06:06:19.523568 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n","I0809 06:06:19.525098 140568367847296 efficientnet_model.py:147] round_filter input=32 output=40\n","I0809 06:06:19.538121 140568367847296 efficientnet_model.py:147] round_filter input=32 output=40\n","I0809 06:06:19.538233 140568367847296 efficientnet_model.py:147] round_filter input=16 output=24\n","I0809 06:06:19.639134 140568367847296 efficientnet_model.py:147] round_filter input=16 output=24\n","I0809 06:06:19.639253 140568367847296 efficientnet_model.py:147] round_filter input=24 output=32\n","I0809 06:06:19.829982 140568367847296 efficientnet_model.py:147] round_filter input=24 output=32\n","I0809 06:06:19.830147 140568367847296 efficientnet_model.py:147] round_filter input=40 output=48\n","I0809 06:06:20.018443 140568367847296 efficientnet_model.py:147] round_filter input=40 output=48\n","I0809 06:06:20.018605 140568367847296 efficientnet_model.py:147] round_filter input=80 output=96\n","I0809 06:06:20.354808 140568367847296 efficientnet_model.py:147] round_filter input=80 output=96\n","I0809 06:06:20.354968 140568367847296 efficientnet_model.py:147] round_filter input=112 output=136\n","I0809 06:06:20.707339 140568367847296 efficientnet_model.py:147] round_filter input=112 output=136\n","I0809 06:06:20.707500 140568367847296 efficientnet_model.py:147] round_filter input=192 output=232\n","I0809 06:06:21.187324 140568367847296 efficientnet_model.py:147] round_filter input=192 output=232\n","I0809 06:06:21.187498 140568367847296 efficientnet_model.py:147] round_filter input=320 output=384\n","I0809 06:06:21.535683 140568367847296 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0809 06:06:21.585198 140568367847296 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0809 06:06:21.646926 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0809 06:06:21.647076 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n","I0809 06:06:21.647148 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0809 06:06:21.648708 140568367847296 efficientnet_model.py:147] round_filter input=32 output=48\n","I0809 06:06:21.661422 140568367847296 efficientnet_model.py:147] round_filter input=32 output=48\n","I0809 06:06:21.661540 140568367847296 efficientnet_model.py:147] round_filter input=16 output=24\n","I0809 06:06:21.764054 140568367847296 efficientnet_model.py:147] round_filter input=16 output=24\n","I0809 06:06:21.764170 140568367847296 efficientnet_model.py:147] round_filter input=24 output=32\n","I0809 06:06:22.020475 140568367847296 efficientnet_model.py:147] round_filter input=24 output=32\n","I0809 06:06:22.020625 140568367847296 efficientnet_model.py:147] round_filter input=40 output=56\n","I0809 06:06:22.282175 140568367847296 efficientnet_model.py:147] round_filter input=40 output=56\n","I0809 06:06:22.282338 140568367847296 efficientnet_model.py:147] round_filter input=80 output=112\n","I0809 06:06:22.696271 140568367847296 efficientnet_model.py:147] round_filter input=80 output=112\n","I0809 06:06:22.696449 140568367847296 efficientnet_model.py:147] round_filter input=112 output=160\n","I0809 06:06:23.136678 140568367847296 efficientnet_model.py:147] round_filter input=112 output=160\n","I0809 06:06:23.136874 140568367847296 efficientnet_model.py:147] round_filter input=192 output=272\n","I0809 06:06:23.833716 140568367847296 efficientnet_model.py:147] round_filter input=192 output=272\n","I0809 06:06:23.833904 140568367847296 efficientnet_model.py:147] round_filter input=320 output=448\n","I0809 06:06:24.051346 140568367847296 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0809 06:06:24.105684 140568367847296 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0809 06:06:24.187375 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0809 06:06:24.187528 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n","I0809 06:06:24.187601 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0809 06:06:24.189215 140568367847296 efficientnet_model.py:147] round_filter input=32 output=48\n","I0809 06:06:24.202458 140568367847296 efficientnet_model.py:147] round_filter input=32 output=48\n","I0809 06:06:24.202574 140568367847296 efficientnet_model.py:147] round_filter input=16 output=24\n","I0809 06:06:24.356471 140568367847296 efficientnet_model.py:147] round_filter input=16 output=24\n","I0809 06:06:24.356606 140568367847296 efficientnet_model.py:147] round_filter input=24 output=40\n","I0809 06:06:24.681807 140568367847296 efficientnet_model.py:147] round_filter input=24 output=40\n","I0809 06:06:24.681966 140568367847296 efficientnet_model.py:147] round_filter input=40 output=64\n","I0809 06:06:25.187465 140568367847296 efficientnet_model.py:147] round_filter input=40 output=64\n","I0809 06:06:25.187636 140568367847296 efficientnet_model.py:147] round_filter input=80 output=128\n","I0809 06:06:25.665950 140568367847296 efficientnet_model.py:147] round_filter input=80 output=128\n","I0809 06:06:25.666126 140568367847296 efficientnet_model.py:147] round_filter input=112 output=176\n","I0809 06:06:26.183258 140568367847296 efficientnet_model.py:147] round_filter input=112 output=176\n","I0809 06:06:26.183429 140568367847296 efficientnet_model.py:147] round_filter input=192 output=304\n","I0809 06:06:27.012229 140568367847296 efficientnet_model.py:147] round_filter input=192 output=304\n","I0809 06:06:27.012417 140568367847296 efficientnet_model.py:147] round_filter input=320 output=512\n","I0809 06:06:27.397410 140568367847296 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0809 06:06:27.462073 140568367847296 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0809 06:06:27.550656 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0809 06:06:27.550841 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0809 06:06:27.550918 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0809 06:06:27.552459 140568367847296 efficientnet_model.py:147] round_filter input=32 output=56\n","I0809 06:06:27.565146 140568367847296 efficientnet_model.py:147] round_filter input=32 output=56\n","I0809 06:06:27.565260 140568367847296 efficientnet_model.py:147] round_filter input=16 output=32\n","I0809 06:06:27.720255 140568367847296 efficientnet_model.py:147] round_filter input=16 output=32\n","I0809 06:06:27.720400 140568367847296 efficientnet_model.py:147] round_filter input=24 output=40\n","I0809 06:06:28.112997 140568367847296 efficientnet_model.py:147] round_filter input=24 output=40\n","I0809 06:06:28.113159 140568367847296 efficientnet_model.py:147] round_filter input=40 output=72\n","I0809 06:06:28.506605 140568367847296 efficientnet_model.py:147] round_filter input=40 output=72\n","I0809 06:06:28.506842 140568367847296 efficientnet_model.py:147] round_filter input=80 output=144\n","I0809 06:06:29.074370 140568367847296 efficientnet_model.py:147] round_filter input=80 output=144\n","I0809 06:06:29.074540 140568367847296 efficientnet_model.py:147] round_filter input=112 output=200\n","I0809 06:06:29.862797 140568367847296 efficientnet_model.py:147] round_filter input=112 output=200\n","I0809 06:06:29.862972 140568367847296 efficientnet_model.py:147] round_filter input=192 output=344\n","I0809 06:06:30.956549 140568367847296 efficientnet_model.py:147] round_filter input=192 output=344\n","I0809 06:06:30.956722 140568367847296 efficientnet_model.py:147] round_filter input=320 output=576\n","I0809 06:06:31.405551 140568367847296 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0809 06:06:31.474258 140568367847296 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0809 06:06:31.577413 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0809 06:06:31.577579 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0809 06:06:31.577656 140568367847296 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0809 06:06:31.579200 140568367847296 efficientnet_model.py:147] round_filter input=32 output=64\n","I0809 06:06:31.592237 140568367847296 efficientnet_model.py:147] round_filter input=32 output=64\n","I0809 06:06:31.592376 140568367847296 efficientnet_model.py:147] round_filter input=16 output=32\n","I0809 06:06:31.803443 140568367847296 efficientnet_model.py:147] round_filter input=16 output=32\n","I0809 06:06:31.803594 140568367847296 efficientnet_model.py:147] round_filter input=24 output=48\n","I0809 06:06:32.267950 140568367847296 efficientnet_model.py:147] round_filter input=24 output=48\n","I0809 06:06:32.268121 140568367847296 efficientnet_model.py:147] round_filter input=40 output=80\n","I0809 06:06:32.748411 140568367847296 efficientnet_model.py:147] round_filter input=40 output=80\n","I0809 06:06:32.748582 140568367847296 efficientnet_model.py:147] round_filter input=80 output=160\n","I0809 06:06:33.486036 140568367847296 efficientnet_model.py:147] round_filter input=80 output=160\n","I0809 06:06:33.486206 140568367847296 efficientnet_model.py:147] round_filter input=112 output=224\n","I0809 06:06:34.486929 140568367847296 efficientnet_model.py:147] round_filter input=112 output=224\n","I0809 06:06:34.487102 140568367847296 efficientnet_model.py:147] round_filter input=192 output=384\n","I0809 06:06:35.889603 140568367847296 efficientnet_model.py:147] round_filter input=192 output=384\n","I0809 06:06:35.889796 140568367847296 efficientnet_model.py:147] round_filter input=320 output=640\n","I0809 06:06:36.591345 140568367847296 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0809 06:06:36.676636 140568367847296 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.38s\n","I0809 06:06:36.788002 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.38s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0809 06:06:36.794427 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0809 06:06:36.796319 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0809 06:06:36.796849 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0809 06:06:36.798301 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0809 06:06:36.799618 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0809 06:06:36.800057 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0809 06:06:36.801006 140568367847296 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 26.562s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xcKiWJhhaHRp"},"source":["# 0. Setup Paths"]},{"cell_type":"code","metadata":{"id":"YZqGcG9qaHRr","executionInfo":{"status":"ok","timestamp":1628488174705,"user_tz":-480,"elapsed":513,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["WORKSPACE_PATH = '/content/TF_Object_Detection/Tensorflow/workspace'\n","SCRIPTS_PATH = '/content/TF_Object_Detection/Tensorflow/scripts'\n","ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n","IMAGE_PATH = WORKSPACE_PATH+'/images'\n","MODEL_PATH = WORKSPACE_PATH+'/models'\n","PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n","CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n","CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EclE9kHscqdf","executionInfo":{"status":"ok","timestamp":1628488001815,"user_tz":-480,"elapsed":5000,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}},"outputId":"c36a74a7-e8b2-40c2-9932-cdea5f903fee"},"source":["!git clone https://github.com/WillyLiew/TF_Object_Detection.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'TF_Object_Detection'...\n","remote: Enumerating objects: 2225, done.\u001b[K\n","remote: Counting objects: 100% (2225/2225), done.\u001b[K\n","remote: Compressing objects: 100% (1581/1581), done.\u001b[K\n","remote: Total 2225 (delta 641), reused 2225 (delta 641), pack-reused 0\u001b[K\n","Receiving objects: 100% (2225/2225), 53.44 MiB | 33.25 MiB/s, done.\n","Resolving deltas: 100% (641/641), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TkEtGO9RaHRt"},"source":["# 1. Create Label Map"]},{"cell_type":"code","metadata":{"id":"LOXNizZLaHRv","executionInfo":{"status":"ok","timestamp":1628488417100,"user_tz":-480,"elapsed":331,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["labels = [{'name':'cat', 'id':1}, {'name':'dog', 'id':2}]\n","\n","with open(ANNOTATION_PATH + '/label_map.pbtxt', 'w') as f:\n","    for label in labels:\n","        f.write('item { \\n')\n","        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n","        f.write('\\tid:{}\\n'.format(label['id']))\n","        f.write('}\\n')"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CLxTslJiaHRw"},"source":["# 2. Create TF records"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGvcBRaYaHRx","executionInfo":{"status":"ok","timestamp":1628490190275,"user_tz":-480,"elapsed":6891,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}},"outputId":"284e5cc6-86a8-4f8f-9814-6628978ddee9"},"source":["!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n","!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x{IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Successfully created the TFRecord file: /content/TF_Object_Detection/Tensorflow/workspace/annotations/train.record\n","Successfully created the TFRecord file: /content/TF_Object_Detection/Tensorflow/workspace/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2bXEcj93aHR1"},"source":["# 3. Download TF Models Pretrained Models from Tensorflow Model Zoo"]},{"cell_type":"code","metadata":{"id":"Yw3WCImUaHR3","outputId":"5a5507bb-6d68-47ec-ec8a-45b817447ddf"},"source":["#Already import model at section 0.0\n","#!cd Tensorflow && git clone https://github.com/tensorflow/models"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'models'...\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6rWqhlQylR01"},"source":["* pre-trained-model already provided as in the github\n"]},{"cell_type":"code","metadata":{"id":"kUbt4AQpaHR6"},"source":["#wget.download('http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz')\n","#!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz {PRETRAINED_MODEL_PATH}\n","#!cd {PRETRAINED_MODEL_PATH} && tar -zxvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NhleJs6VaHR7"},"source":["# 4. Copy Model Config to Training Folder"]},{"cell_type":"code","metadata":{"id":"dbkl7mO8aHR8","executionInfo":{"status":"ok","timestamp":1628490293851,"user_tz":-480,"elapsed":365,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["CUSTOM_MODEL_NAME = 'my_ssd_mobnet' "],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGBl2-6JaHR9","executionInfo":{"status":"ok","timestamp":1628490864904,"user_tz":-480,"elapsed":432,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["!mkdir {'/content/TF_Object_Detection/Tensorflow/workspace/models/'+CUSTOM_MODEL_NAME}\n","!cp {PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'} {MODEL_PATH+'/'+CUSTOM_MODEL_NAME}"],"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19-NQSXwaHR-"},"source":["# 5. Update Config For Transfer Learning"]},{"cell_type":"code","metadata":{"id":"yoKnoOf8aHR_","executionInfo":{"status":"ok","timestamp":1628490370948,"user_tz":-480,"elapsed":395,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8gE754GaHSA","executionInfo":{"status":"ok","timestamp":1628490374974,"user_tz":-480,"elapsed":468,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-u5_ZqVaHSA","executionInfo":{"status":"ok","timestamp":1628490874588,"user_tz":-480,"elapsed":355,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"wnDSvw5XaHSB","outputId":"813976ce-4219-4266-e409-2fb693211d2c"},"source":["config"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'model': ssd {\n","   num_classes: 2\n","   image_resizer {\n","     fixed_shape_resizer {\n","       height: 320\n","       width: 320\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_mobilenet_v2_fpn_keras\"\n","     depth_multiplier: 1.0\n","     min_depth: 16\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 4e-05\n","         }\n","       }\n","       initializer {\n","         random_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.01\n","         }\n","       }\n","       activation: RELU_6\n","       batch_norm {\n","         decay: 0.997\n","         scale: true\n","         epsilon: 0.001\n","       }\n","     }\n","     use_depthwise: true\n","     override_base_feature_extractor_hyperparams: true\n","     fpn {\n","       min_level: 3\n","       max_level: 7\n","       additional_layer_depth: 128\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 4e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.01\n","           }\n","         }\n","         activation: RELU_6\n","         batch_norm {\n","           decay: 0.997\n","           scale: true\n","           epsilon: 0.001\n","         }\n","       }\n","       depth: 128\n","       num_layers_before_predictor: 4\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.6\n","       share_prediction_tower: true\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 2\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 1e-08\n","       iou_threshold: 0.6\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","       use_static_shapes: false\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 2.0\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n"," }, 'train_config': batch_size: 4\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_crop_image {\n","     min_object_covered: 0.0\n","     min_aspect_ratio: 0.75\n","     max_aspect_ratio: 3.0\n","     min_area: 0.75\n","     max_area: 1.0\n","     overlap_thresh: 0.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.08\n","         total_steps: 50000\n","         warmup_learning_rate: 0.026666\n","         warmup_steps: 1000\n","       }\n","     }\n","     momentum_optimizer_value: 0.9\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n"," num_steps: 50000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"detection\"\n"," fine_tune_checkpoint_version: V2, 'train_input_config': label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n"," tf_record_input_reader {\n","   input_path: \"Tensorflow/workspace/annotations/train.record\"\n"," }, 'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false, 'eval_input_configs': [label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"Tensorflow/workspace/annotations/test.record\"\n"," }\n"," ], 'eval_input_config': label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"Tensorflow/workspace/annotations/test.record\"\n"," }}"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"62pUAEoTaHSB","executionInfo":{"status":"ok","timestamp":1628494103928,"user_tz":-480,"elapsed":4,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)  "],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPt9VuGqaHSC","executionInfo":{"status":"ok","timestamp":1628494105878,"user_tz":-480,"elapsed":5,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["pipeline_config.model.ssd.num_classes = 2\n","pipeline_config.train_config.batch_size = 4\n","pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n","pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + '/label_map.pbtxt'\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n","pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sx8v4T9CaHSD","executionInfo":{"status":"ok","timestamp":1628494108448,"user_tz":-480,"elapsed":338,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n","    f.write(config_text)   "],"execution_count":69,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gL58KkIPaHSE"},"source":["# 6. Train the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOEwTKRJaHSF","executionInfo":{"status":"ok","timestamp":1628502347330,"user_tz":-480,"elapsed":8236723,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}},"outputId":"140982ae-5ec8-42da-b238-0ddb15c7696e"},"source":["!python /content/models/research/object_detection/model_main_tf2.py --model_dir=/content/TF_Object_Detection/Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=/content/TF_Object_Detection/Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=5000"],"execution_count":70,"outputs":[{"output_type":"stream","text":["2021-08-09 07:28:30.907787: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","2021-08-09 07:28:33.021018: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n","2021-08-09 07:28:33.050221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-09 07:28:33.050839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-08-09 07:28:33.050883: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","2021-08-09 07:28:33.053859: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n","2021-08-09 07:28:33.053953: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n","2021-08-09 07:28:33.056016: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n","2021-08-09 07:28:33.056386: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n","2021-08-09 07:28:33.056493: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2021-08-09 07:28:33.057106: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n","2021-08-09 07:28:33.057299: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n","2021-08-09 07:28:33.057328: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2021-08-09 07:28:33.057700: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-08-09 07:28:33.057865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-08-09 07:28:33.057891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n","WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","W0809 07:28:33.058483 140353392334720 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n","W0809 07:28:33.058794 140353392334720 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","I0809 07:28:33.060936 140353392334720 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 5000\n","I0809 07:28:33.065241 140353392334720 config_util.py:552] Maybe overwriting train_steps: 5000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0809 07:28:33.065390 140353392334720 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0809 07:28:33.086451 140353392334720 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/TF_Object_Detection/Tensorflow/workspace/annotations/train.record']\n","I0809 07:28:33.089930 140353392334720 dataset_builder.py:163] Reading unweighted datasets: ['/content/TF_Object_Detection/Tensorflow/workspace/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/TF_Object_Detection/Tensorflow/workspace/annotations/train.record']\n","I0809 07:28:33.090104 140353392334720 dataset_builder.py:80] Reading record datasets for input file: ['/content/TF_Object_Detection/Tensorflow/workspace/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0809 07:28:33.090191 140353392334720 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0809 07:28:33.090264 140353392334720 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0809 07:28:33.092323 140353392334720 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0809 07:28:33.110704 140353392334720 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0809 07:28:39.829009 140353392334720 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0809 07:28:42.844495 140353392334720 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0809 07:28:44.445000 140353392334720 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-08-09 07:28:46.616995: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n","2021-08-09 07:28:46.622657: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0809 07:29:07.927152 140350313887488 deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 1.947s\n","I0809 07:32:22.232657 140353392334720 model_lib_v2.py:700] Step 100 per-step time 1.947s\n","INFO:tensorflow:{'Loss/classification_loss': 0.42106587,\n"," 'Loss/localization_loss': 0.3098428,\n"," 'Loss/regularization_loss': 0.15427783,\n"," 'Loss/total_loss': 0.8851865,\n"," 'learning_rate': 0.0319994}\n","I0809 07:32:22.233117 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.42106587,\n"," 'Loss/localization_loss': 0.3098428,\n"," 'Loss/regularization_loss': 0.15427783,\n"," 'Loss/total_loss': 0.8851865,\n"," 'learning_rate': 0.0319994}\n","INFO:tensorflow:Step 200 per-step time 1.649s\n","I0809 07:35:07.109441 140353392334720 model_lib_v2.py:700] Step 200 per-step time 1.649s\n","INFO:tensorflow:{'Loss/classification_loss': 0.32698938,\n"," 'Loss/localization_loss': 0.18418033,\n"," 'Loss/regularization_loss': 0.15436697,\n"," 'Loss/total_loss': 0.66553664,\n"," 'learning_rate': 0.0373328}\n","I0809 07:35:07.109860 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.32698938,\n"," 'Loss/localization_loss': 0.18418033,\n"," 'Loss/regularization_loss': 0.15436697,\n"," 'Loss/total_loss': 0.66553664,\n"," 'learning_rate': 0.0373328}\n","INFO:tensorflow:Step 300 per-step time 1.664s\n","I0809 07:37:53.511156 140353392334720 model_lib_v2.py:700] Step 300 per-step time 1.664s\n","INFO:tensorflow:{'Loss/classification_loss': 0.26040572,\n"," 'Loss/localization_loss': 0.24733952,\n"," 'Loss/regularization_loss': 0.15426406,\n"," 'Loss/total_loss': 0.6620093,\n"," 'learning_rate': 0.0426662}\n","I0809 07:37:53.511521 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.26040572,\n"," 'Loss/localization_loss': 0.24733952,\n"," 'Loss/regularization_loss': 0.15426406,\n"," 'Loss/total_loss': 0.6620093,\n"," 'learning_rate': 0.0426662}\n","INFO:tensorflow:Step 400 per-step time 1.653s\n","I0809 07:40:38.807577 140353392334720 model_lib_v2.py:700] Step 400 per-step time 1.653s\n","INFO:tensorflow:{'Loss/classification_loss': 0.40277728,\n"," 'Loss/localization_loss': 0.28741655,\n"," 'Loss/regularization_loss': 0.15421651,\n"," 'Loss/total_loss': 0.8444103,\n"," 'learning_rate': 0.047999598}\n","I0809 07:40:38.807955 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.40277728,\n"," 'Loss/localization_loss': 0.28741655,\n"," 'Loss/regularization_loss': 0.15421651,\n"," 'Loss/total_loss': 0.8444103,\n"," 'learning_rate': 0.047999598}\n","INFO:tensorflow:Step 500 per-step time 1.649s\n","I0809 07:43:23.674601 140353392334720 model_lib_v2.py:700] Step 500 per-step time 1.649s\n","INFO:tensorflow:{'Loss/classification_loss': 0.27817318,\n"," 'Loss/localization_loss': 0.07537694,\n"," 'Loss/regularization_loss': 0.15418486,\n"," 'Loss/total_loss': 0.507735,\n"," 'learning_rate': 0.053333}\n","I0809 07:43:23.674978 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.27817318,\n"," 'Loss/localization_loss': 0.07537694,\n"," 'Loss/regularization_loss': 0.15418486,\n"," 'Loss/total_loss': 0.507735,\n"," 'learning_rate': 0.053333}\n","INFO:tensorflow:Step 600 per-step time 1.640s\n","I0809 07:46:07.700205 140353392334720 model_lib_v2.py:700] Step 600 per-step time 1.640s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2837328,\n"," 'Loss/localization_loss': 0.22090672,\n"," 'Loss/regularization_loss': 0.15406393,\n"," 'Loss/total_loss': 0.65870345,\n"," 'learning_rate': 0.0586664}\n","I0809 07:46:07.700593 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.2837328,\n"," 'Loss/localization_loss': 0.22090672,\n"," 'Loss/regularization_loss': 0.15406393,\n"," 'Loss/total_loss': 0.65870345,\n"," 'learning_rate': 0.0586664}\n","INFO:tensorflow:Step 700 per-step time 1.649s\n","I0809 07:48:52.609961 140353392334720 model_lib_v2.py:700] Step 700 per-step time 1.649s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2562752,\n"," 'Loss/localization_loss': 0.13811527,\n"," 'Loss/regularization_loss': 0.15414377,\n"," 'Loss/total_loss': 0.5485343,\n"," 'learning_rate': 0.0639998}\n","I0809 07:48:52.610342 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.2562752,\n"," 'Loss/localization_loss': 0.13811527,\n"," 'Loss/regularization_loss': 0.15414377,\n"," 'Loss/total_loss': 0.5485343,\n"," 'learning_rate': 0.0639998}\n","INFO:tensorflow:Step 800 per-step time 1.646s\n","I0809 07:51:37.226577 140353392334720 model_lib_v2.py:700] Step 800 per-step time 1.646s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22133566,\n"," 'Loss/localization_loss': 0.15812695,\n"," 'Loss/regularization_loss': 0.15424922,\n"," 'Loss/total_loss': 0.53371185,\n"," 'learning_rate': 0.069333196}\n","I0809 07:51:37.226955 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.22133566,\n"," 'Loss/localization_loss': 0.15812695,\n"," 'Loss/regularization_loss': 0.15424922,\n"," 'Loss/total_loss': 0.53371185,\n"," 'learning_rate': 0.069333196}\n","INFO:tensorflow:Step 900 per-step time 1.645s\n","I0809 07:54:21.724058 140353392334720 model_lib_v2.py:700] Step 900 per-step time 1.645s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21781914,\n"," 'Loss/localization_loss': 0.08818837,\n"," 'Loss/regularization_loss': 0.15432097,\n"," 'Loss/total_loss': 0.46032846,\n"," 'learning_rate': 0.074666604}\n","I0809 07:54:21.724428 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.21781914,\n"," 'Loss/localization_loss': 0.08818837,\n"," 'Loss/regularization_loss': 0.15432097,\n"," 'Loss/total_loss': 0.46032846,\n"," 'learning_rate': 0.074666604}\n","INFO:tensorflow:Step 1000 per-step time 1.625s\n","I0809 07:57:04.190180 140353392334720 model_lib_v2.py:700] Step 1000 per-step time 1.625s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17439595,\n"," 'Loss/localization_loss': 0.12391113,\n"," 'Loss/regularization_loss': 0.1543604,\n"," 'Loss/total_loss': 0.45266747,\n"," 'learning_rate': 0.08}\n","I0809 07:57:04.190593 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.17439595,\n"," 'Loss/localization_loss': 0.12391113,\n"," 'Loss/regularization_loss': 0.1543604,\n"," 'Loss/total_loss': 0.45266747,\n"," 'learning_rate': 0.08}\n","INFO:tensorflow:Step 1100 per-step time 1.647s\n","I0809 07:59:48.866230 140353392334720 model_lib_v2.py:700] Step 1100 per-step time 1.647s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20892526,\n"," 'Loss/localization_loss': 0.11064283,\n"," 'Loss/regularization_loss': 0.15438212,\n"," 'Loss/total_loss': 0.4739502,\n"," 'learning_rate': 0.07999918}\n","I0809 07:59:48.866634 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.20892526,\n"," 'Loss/localization_loss': 0.11064283,\n"," 'Loss/regularization_loss': 0.15438212,\n"," 'Loss/total_loss': 0.4739502,\n"," 'learning_rate': 0.07999918}\n","INFO:tensorflow:Step 1200 per-step time 1.640s\n","I0809 08:02:32.816951 140353392334720 model_lib_v2.py:700] Step 1200 per-step time 1.640s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3024814,\n"," 'Loss/localization_loss': 0.085148655,\n"," 'Loss/regularization_loss': 0.1541227,\n"," 'Loss/total_loss': 0.54175276,\n"," 'learning_rate': 0.079996705}\n","I0809 08:02:32.817306 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.3024814,\n"," 'Loss/localization_loss': 0.085148655,\n"," 'Loss/regularization_loss': 0.1541227,\n"," 'Loss/total_loss': 0.54175276,\n"," 'learning_rate': 0.079996705}\n","INFO:tensorflow:Step 1300 per-step time 1.650s\n","I0809 08:05:17.815453 140353392334720 model_lib_v2.py:700] Step 1300 per-step time 1.650s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18954383,\n"," 'Loss/localization_loss': 0.11373412,\n"," 'Loss/regularization_loss': 0.15403688,\n"," 'Loss/total_loss': 0.45731485,\n"," 'learning_rate': 0.0799926}\n","I0809 08:05:17.815971 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.18954383,\n"," 'Loss/localization_loss': 0.11373412,\n"," 'Loss/regularization_loss': 0.15403688,\n"," 'Loss/total_loss': 0.45731485,\n"," 'learning_rate': 0.0799926}\n","INFO:tensorflow:Step 1400 per-step time 1.623s\n","I0809 08:08:00.154442 140353392334720 model_lib_v2.py:700] Step 1400 per-step time 1.623s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4060335,\n"," 'Loss/localization_loss': 0.28491583,\n"," 'Loss/regularization_loss': 0.15394214,\n"," 'Loss/total_loss': 0.8448914,\n"," 'learning_rate': 0.07998685}\n","I0809 08:08:00.154847 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.4060335,\n"," 'Loss/localization_loss': 0.28491583,\n"," 'Loss/regularization_loss': 0.15394214,\n"," 'Loss/total_loss': 0.8448914,\n"," 'learning_rate': 0.07998685}\n","INFO:tensorflow:Step 1500 per-step time 1.646s\n","I0809 08:10:44.798808 140353392334720 model_lib_v2.py:700] Step 1500 per-step time 1.646s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2872612,\n"," 'Loss/localization_loss': 0.19533068,\n"," 'Loss/regularization_loss': 0.15381227,\n"," 'Loss/total_loss': 0.63640416,\n"," 'learning_rate': 0.07997945}\n","I0809 08:10:44.799183 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.2872612,\n"," 'Loss/localization_loss': 0.19533068,\n"," 'Loss/regularization_loss': 0.15381227,\n"," 'Loss/total_loss': 0.63640416,\n"," 'learning_rate': 0.07997945}\n","INFO:tensorflow:Step 1600 per-step time 1.637s\n","I0809 08:13:28.517667 140353392334720 model_lib_v2.py:700] Step 1600 per-step time 1.637s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3126109,\n"," 'Loss/localization_loss': 0.12272841,\n"," 'Loss/regularization_loss': 0.15358563,\n"," 'Loss/total_loss': 0.5889249,\n"," 'learning_rate': 0.079970405}\n","I0809 08:13:28.518056 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.3126109,\n"," 'Loss/localization_loss': 0.12272841,\n"," 'Loss/regularization_loss': 0.15358563,\n"," 'Loss/total_loss': 0.5889249,\n"," 'learning_rate': 0.079970405}\n","INFO:tensorflow:Step 1700 per-step time 1.635s\n","I0809 08:16:12.046733 140353392334720 model_lib_v2.py:700] Step 1700 per-step time 1.635s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22482373,\n"," 'Loss/localization_loss': 0.21783422,\n"," 'Loss/regularization_loss': 0.15351588,\n"," 'Loss/total_loss': 0.5961738,\n"," 'learning_rate': 0.07995972}\n","I0809 08:16:12.047116 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.22482373,\n"," 'Loss/localization_loss': 0.21783422,\n"," 'Loss/regularization_loss': 0.15351588,\n"," 'Loss/total_loss': 0.5961738,\n"," 'learning_rate': 0.07995972}\n","INFO:tensorflow:Step 1800 per-step time 1.606s\n","I0809 08:18:52.659955 140353392334720 model_lib_v2.py:700] Step 1800 per-step time 1.606s\n","INFO:tensorflow:{'Loss/classification_loss': 0.26507112,\n"," 'Loss/localization_loss': 0.14806652,\n"," 'Loss/regularization_loss': 0.15331966,\n"," 'Loss/total_loss': 0.5664573,\n"," 'learning_rate': 0.0799474}\n","I0809 08:18:52.660312 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.26507112,\n"," 'Loss/localization_loss': 0.14806652,\n"," 'Loss/regularization_loss': 0.15331966,\n"," 'Loss/total_loss': 0.5664573,\n"," 'learning_rate': 0.0799474}\n","INFO:tensorflow:Step 1900 per-step time 1.641s\n","I0809 08:21:36.727512 140353392334720 model_lib_v2.py:700] Step 1900 per-step time 1.641s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16054447,\n"," 'Loss/localization_loss': 0.09115139,\n"," 'Loss/regularization_loss': 0.15309279,\n"," 'Loss/total_loss': 0.40478864,\n"," 'learning_rate': 0.07993342}\n","I0809 08:21:36.727884 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.16054447,\n"," 'Loss/localization_loss': 0.09115139,\n"," 'Loss/regularization_loss': 0.15309279,\n"," 'Loss/total_loss': 0.40478864,\n"," 'learning_rate': 0.07993342}\n","INFO:tensorflow:Step 2000 per-step time 1.654s\n","I0809 08:24:22.168307 140353392334720 model_lib_v2.py:700] Step 2000 per-step time 1.654s\n","INFO:tensorflow:{'Loss/classification_loss': 0.100540005,\n"," 'Loss/localization_loss': 0.05528221,\n"," 'Loss/regularization_loss': 0.15275893,\n"," 'Loss/total_loss': 0.30858114,\n"," 'learning_rate': 0.07991781}\n","I0809 08:24:22.168663 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.100540005,\n"," 'Loss/localization_loss': 0.05528221,\n"," 'Loss/regularization_loss': 0.15275893,\n"," 'Loss/total_loss': 0.30858114,\n"," 'learning_rate': 0.07991781}\n","INFO:tensorflow:Step 2100 per-step time 1.666s\n","I0809 08:27:08.798540 140353392334720 model_lib_v2.py:700] Step 2100 per-step time 1.666s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1922025,\n"," 'Loss/localization_loss': 0.090207145,\n"," 'Loss/regularization_loss': 0.15268268,\n"," 'Loss/total_loss': 0.43509233,\n"," 'learning_rate': 0.07990056}\n","I0809 08:27:08.798941 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.1922025,\n"," 'Loss/localization_loss': 0.090207145,\n"," 'Loss/regularization_loss': 0.15268268,\n"," 'Loss/total_loss': 0.43509233,\n"," 'learning_rate': 0.07990056}\n","INFO:tensorflow:Step 2200 per-step time 1.621s\n","I0809 08:29:50.936601 140353392334720 model_lib_v2.py:700] Step 2200 per-step time 1.621s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15914407,\n"," 'Loss/localization_loss': 0.083274364,\n"," 'Loss/regularization_loss': 0.15255612,\n"," 'Loss/total_loss': 0.39497456,\n"," 'learning_rate': 0.07988167}\n","I0809 08:29:50.937014 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.15914407,\n"," 'Loss/localization_loss': 0.083274364,\n"," 'Loss/regularization_loss': 0.15255612,\n"," 'Loss/total_loss': 0.39497456,\n"," 'learning_rate': 0.07988167}\n","INFO:tensorflow:Step 2300 per-step time 1.659s\n","I0809 08:32:36.872703 140353392334720 model_lib_v2.py:700] Step 2300 per-step time 1.659s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18988545,\n"," 'Loss/localization_loss': 0.104963824,\n"," 'Loss/regularization_loss': 0.1523911,\n"," 'Loss/total_loss': 0.44724035,\n"," 'learning_rate': 0.07986114}\n","I0809 08:32:36.873231 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.18988545,\n"," 'Loss/localization_loss': 0.104963824,\n"," 'Loss/regularization_loss': 0.1523911,\n"," 'Loss/total_loss': 0.44724035,\n"," 'learning_rate': 0.07986114}\n","INFO:tensorflow:Step 2400 per-step time 1.666s\n","I0809 08:35:23.437296 140353392334720 model_lib_v2.py:700] Step 2400 per-step time 1.666s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2244724,\n"," 'Loss/localization_loss': 0.14728238,\n"," 'Loss/regularization_loss': 0.15212113,\n"," 'Loss/total_loss': 0.5238759,\n"," 'learning_rate': 0.07983897}\n","I0809 08:35:23.437657 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.2244724,\n"," 'Loss/localization_loss': 0.14728238,\n"," 'Loss/regularization_loss': 0.15212113,\n"," 'Loss/total_loss': 0.5238759,\n"," 'learning_rate': 0.07983897}\n","INFO:tensorflow:Step 2500 per-step time 1.650s\n","I0809 08:38:08.419187 140353392334720 model_lib_v2.py:700] Step 2500 per-step time 1.650s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15690574,\n"," 'Loss/localization_loss': 0.030275287,\n"," 'Loss/regularization_loss': 0.15193313,\n"," 'Loss/total_loss': 0.33911416,\n"," 'learning_rate': 0.079815164}\n","I0809 08:38:08.419530 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.15690574,\n"," 'Loss/localization_loss': 0.030275287,\n"," 'Loss/regularization_loss': 0.15193313,\n"," 'Loss/total_loss': 0.33911416,\n"," 'learning_rate': 0.079815164}\n","INFO:tensorflow:Step 2600 per-step time 1.613s\n","I0809 08:40:49.734097 140353392334720 model_lib_v2.py:700] Step 2600 per-step time 1.613s\n","INFO:tensorflow:{'Loss/classification_loss': 0.28788963,\n"," 'Loss/localization_loss': 0.031416886,\n"," 'Loss/regularization_loss': 0.15170753,\n"," 'Loss/total_loss': 0.47101405,\n"," 'learning_rate': 0.07978972}\n","I0809 08:40:49.734488 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.28788963,\n"," 'Loss/localization_loss': 0.031416886,\n"," 'Loss/regularization_loss': 0.15170753,\n"," 'Loss/total_loss': 0.47101405,\n"," 'learning_rate': 0.07978972}\n","INFO:tensorflow:Step 2700 per-step time 1.645s\n","I0809 08:43:34.212905 140353392334720 model_lib_v2.py:700] Step 2700 per-step time 1.645s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15862983,\n"," 'Loss/localization_loss': 0.052914206,\n"," 'Loss/regularization_loss': 0.15143634,\n"," 'Loss/total_loss': 0.36298037,\n"," 'learning_rate': 0.07976264}\n","I0809 08:43:34.213307 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.15862983,\n"," 'Loss/localization_loss': 0.052914206,\n"," 'Loss/regularization_loss': 0.15143634,\n"," 'Loss/total_loss': 0.36298037,\n"," 'learning_rate': 0.07976264}\n","INFO:tensorflow:Step 2800 per-step time 1.643s\n","I0809 08:46:18.535813 140353392334720 model_lib_v2.py:700] Step 2800 per-step time 1.643s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13688605,\n"," 'Loss/localization_loss': 0.06649161,\n"," 'Loss/regularization_loss': 0.15112707,\n"," 'Loss/total_loss': 0.3545047,\n"," 'learning_rate': 0.07973392}\n","I0809 08:46:18.536156 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.13688605,\n"," 'Loss/localization_loss': 0.06649161,\n"," 'Loss/regularization_loss': 0.15112707,\n"," 'Loss/total_loss': 0.3545047,\n"," 'learning_rate': 0.07973392}\n","INFO:tensorflow:Step 2900 per-step time 1.636s\n","I0809 08:49:02.172253 140353392334720 model_lib_v2.py:700] Step 2900 per-step time 1.636s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18849526,\n"," 'Loss/localization_loss': 0.08850394,\n"," 'Loss/regularization_loss': 0.1509204,\n"," 'Loss/total_loss': 0.42791963,\n"," 'learning_rate': 0.07970358}\n","I0809 08:49:02.172628 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.18849526,\n"," 'Loss/localization_loss': 0.08850394,\n"," 'Loss/regularization_loss': 0.1509204,\n"," 'Loss/total_loss': 0.42791963,\n"," 'learning_rate': 0.07970358}\n","INFO:tensorflow:Step 3000 per-step time 1.611s\n","I0809 08:51:43.244901 140353392334720 model_lib_v2.py:700] Step 3000 per-step time 1.611s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21674809,\n"," 'Loss/localization_loss': 0.105533116,\n"," 'Loss/regularization_loss': 0.15076359,\n"," 'Loss/total_loss': 0.47304478,\n"," 'learning_rate': 0.0796716}\n","I0809 08:51:43.245261 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.21674809,\n"," 'Loss/localization_loss': 0.105533116,\n"," 'Loss/regularization_loss': 0.15076359,\n"," 'Loss/total_loss': 0.47304478,\n"," 'learning_rate': 0.0796716}\n","INFO:tensorflow:Step 3100 per-step time 1.641s\n","I0809 08:54:27.363167 140353392334720 model_lib_v2.py:700] Step 3100 per-step time 1.641s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2130537,\n"," 'Loss/localization_loss': 0.25841507,\n"," 'Loss/regularization_loss': 0.15055299,\n"," 'Loss/total_loss': 0.6220218,\n"," 'learning_rate': 0.07963799}\n","I0809 08:54:27.363544 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.2130537,\n"," 'Loss/localization_loss': 0.25841507,\n"," 'Loss/regularization_loss': 0.15055299,\n"," 'Loss/total_loss': 0.6220218,\n"," 'learning_rate': 0.07963799}\n","INFO:tensorflow:Step 3200 per-step time 1.616s\n","I0809 08:57:08.958475 140353392334720 model_lib_v2.py:700] Step 3200 per-step time 1.616s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21692486,\n"," 'Loss/localization_loss': 0.11213799,\n"," 'Loss/regularization_loss': 0.15038584,\n"," 'Loss/total_loss': 0.47944868,\n"," 'learning_rate': 0.07960275}\n","I0809 08:57:08.958877 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.21692486,\n"," 'Loss/localization_loss': 0.11213799,\n"," 'Loss/regularization_loss': 0.15038584,\n"," 'Loss/total_loss': 0.47944868,\n"," 'learning_rate': 0.07960275}\n","INFO:tensorflow:Step 3300 per-step time 1.630s\n","I0809 08:59:51.917630 140353392334720 model_lib_v2.py:700] Step 3300 per-step time 1.630s\n","INFO:tensorflow:{'Loss/classification_loss': 0.10483683,\n"," 'Loss/localization_loss': 0.02901071,\n"," 'Loss/regularization_loss': 0.1500486,\n"," 'Loss/total_loss': 0.28389615,\n"," 'learning_rate': 0.07956588}\n","I0809 08:59:51.918001 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.10483683,\n"," 'Loss/localization_loss': 0.02901071,\n"," 'Loss/regularization_loss': 0.1500486,\n"," 'Loss/total_loss': 0.28389615,\n"," 'learning_rate': 0.07956588}\n","INFO:tensorflow:Step 3400 per-step time 1.624s\n","I0809 09:02:34.273052 140353392334720 model_lib_v2.py:700] Step 3400 per-step time 1.624s\n","INFO:tensorflow:{'Loss/classification_loss': 0.327702,\n"," 'Loss/localization_loss': 0.19337961,\n"," 'Loss/regularization_loss': 0.14976147,\n"," 'Loss/total_loss': 0.67084306,\n"," 'learning_rate': 0.079527386}\n","I0809 09:02:34.273413 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.327702,\n"," 'Loss/localization_loss': 0.19337961,\n"," 'Loss/regularization_loss': 0.14976147,\n"," 'Loss/total_loss': 0.67084306,\n"," 'learning_rate': 0.079527386}\n","INFO:tensorflow:Step 3500 per-step time 1.617s\n","I0809 09:05:15.952993 140353392334720 model_lib_v2.py:700] Step 3500 per-step time 1.617s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1375648,\n"," 'Loss/localization_loss': 0.06075322,\n"," 'Loss/regularization_loss': 0.1495656,\n"," 'Loss/total_loss': 0.34788364,\n"," 'learning_rate': 0.07948727}\n","I0809 09:05:15.953355 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.1375648,\n"," 'Loss/localization_loss': 0.06075322,\n"," 'Loss/regularization_loss': 0.1495656,\n"," 'Loss/total_loss': 0.34788364,\n"," 'learning_rate': 0.07948727}\n","INFO:tensorflow:Step 3600 per-step time 1.609s\n","I0809 09:07:56.882383 140353392334720 model_lib_v2.py:700] Step 3600 per-step time 1.609s\n","INFO:tensorflow:{'Loss/classification_loss': 0.24374212,\n"," 'Loss/localization_loss': 0.04776554,\n"," 'Loss/regularization_loss': 0.14958505,\n"," 'Loss/total_loss': 0.44109273,\n"," 'learning_rate': 0.079445526}\n","I0809 09:07:56.882731 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.24374212,\n"," 'Loss/localization_loss': 0.04776554,\n"," 'Loss/regularization_loss': 0.14958505,\n"," 'Loss/total_loss': 0.44109273,\n"," 'learning_rate': 0.079445526}\n","INFO:tensorflow:Step 3700 per-step time 1.633s\n","I0809 09:10:40.220911 140353392334720 model_lib_v2.py:700] Step 3700 per-step time 1.633s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17688492,\n"," 'Loss/localization_loss': 0.09053327,\n"," 'Loss/regularization_loss': 0.14942323,\n"," 'Loss/total_loss': 0.41684142,\n"," 'learning_rate': 0.07940216}\n","I0809 09:10:40.221256 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.17688492,\n"," 'Loss/localization_loss': 0.09053327,\n"," 'Loss/regularization_loss': 0.14942323,\n"," 'Loss/total_loss': 0.41684142,\n"," 'learning_rate': 0.07940216}\n","INFO:tensorflow:Step 3800 per-step time 1.632s\n","I0809 09:13:23.425307 140353392334720 model_lib_v2.py:700] Step 3800 per-step time 1.632s\n","INFO:tensorflow:{'Loss/classification_loss': 0.23254493,\n"," 'Loss/localization_loss': 0.058754425,\n"," 'Loss/regularization_loss': 0.14915782,\n"," 'Loss/total_loss': 0.44045717,\n"," 'learning_rate': 0.079357184}\n","I0809 09:13:23.425652 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.23254493,\n"," 'Loss/localization_loss': 0.058754425,\n"," 'Loss/regularization_loss': 0.14915782,\n"," 'Loss/total_loss': 0.44045717,\n"," 'learning_rate': 0.079357184}\n","INFO:tensorflow:Step 3900 per-step time 1.613s\n","I0809 09:16:04.741188 140353392334720 model_lib_v2.py:700] Step 3900 per-step time 1.613s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16493484,\n"," 'Loss/localization_loss': 0.07882626,\n"," 'Loss/regularization_loss': 0.14893278,\n"," 'Loss/total_loss': 0.39269388,\n"," 'learning_rate': 0.07931058}\n","I0809 09:16:04.741568 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.16493484,\n"," 'Loss/localization_loss': 0.07882626,\n"," 'Loss/regularization_loss': 0.14893278,\n"," 'Loss/total_loss': 0.39269388,\n"," 'learning_rate': 0.07931058}\n","INFO:tensorflow:Step 4000 per-step time 1.584s\n","I0809 09:18:43.165334 140353392334720 model_lib_v2.py:700] Step 4000 per-step time 1.584s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17303881,\n"," 'Loss/localization_loss': 0.07493056,\n"," 'Loss/regularization_loss': 0.14874807,\n"," 'Loss/total_loss': 0.39671743,\n"," 'learning_rate': 0.07926236}\n","I0809 09:18:43.165697 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.17303881,\n"," 'Loss/localization_loss': 0.07493056,\n"," 'Loss/regularization_loss': 0.14874807,\n"," 'Loss/total_loss': 0.39671743,\n"," 'learning_rate': 0.07926236}\n","INFO:tensorflow:Step 4100 per-step time 1.624s\n","I0809 09:21:25.613073 140353392334720 model_lib_v2.py:700] Step 4100 per-step time 1.624s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20056142,\n"," 'Loss/localization_loss': 0.099653766,\n"," 'Loss/regularization_loss': 0.14854965,\n"," 'Loss/total_loss': 0.44876483,\n"," 'learning_rate': 0.07921253}\n","I0809 09:21:25.613436 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.20056142,\n"," 'Loss/localization_loss': 0.099653766,\n"," 'Loss/regularization_loss': 0.14854965,\n"," 'Loss/total_loss': 0.44876483,\n"," 'learning_rate': 0.07921253}\n","INFO:tensorflow:Step 4200 per-step time 1.625s\n","I0809 09:24:08.090784 140353392334720 model_lib_v2.py:700] Step 4200 per-step time 1.625s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16046275,\n"," 'Loss/localization_loss': 0.03635794,\n"," 'Loss/regularization_loss': 0.1487874,\n"," 'Loss/total_loss': 0.3456081,\n"," 'learning_rate': 0.07916109}\n","I0809 09:24:08.091190 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.16046275,\n"," 'Loss/localization_loss': 0.03635794,\n"," 'Loss/regularization_loss': 0.1487874,\n"," 'Loss/total_loss': 0.3456081,\n"," 'learning_rate': 0.07916109}\n","INFO:tensorflow:Step 4300 per-step time 1.628s\n","I0809 09:26:50.847141 140353392334720 model_lib_v2.py:700] Step 4300 per-step time 1.628s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17779644,\n"," 'Loss/localization_loss': 0.10464993,\n"," 'Loss/regularization_loss': 0.14864245,\n"," 'Loss/total_loss': 0.4310888,\n"," 'learning_rate': 0.07910804}\n","I0809 09:26:50.847531 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.17779644,\n"," 'Loss/localization_loss': 0.10464993,\n"," 'Loss/regularization_loss': 0.14864245,\n"," 'Loss/total_loss': 0.4310888,\n"," 'learning_rate': 0.07910804}\n","INFO:tensorflow:Step 4400 per-step time 1.626s\n","I0809 09:29:33.470719 140353392334720 model_lib_v2.py:700] Step 4400 per-step time 1.626s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14554898,\n"," 'Loss/localization_loss': 0.059911203,\n"," 'Loss/regularization_loss': 0.14850682,\n"," 'Loss/total_loss': 0.353967,\n"," 'learning_rate': 0.07905338}\n","I0809 09:29:33.471094 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.14554898,\n"," 'Loss/localization_loss': 0.059911203,\n"," 'Loss/regularization_loss': 0.14850682,\n"," 'Loss/total_loss': 0.353967,\n"," 'learning_rate': 0.07905338}\n","INFO:tensorflow:Step 4500 per-step time 1.611s\n","I0809 09:32:14.570958 140353392334720 model_lib_v2.py:700] Step 4500 per-step time 1.611s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15448222,\n"," 'Loss/localization_loss': 0.1387372,\n"," 'Loss/regularization_loss': 0.14825115,\n"," 'Loss/total_loss': 0.44147056,\n"," 'learning_rate': 0.07899711}\n","I0809 09:32:14.571323 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.15448222,\n"," 'Loss/localization_loss': 0.1387372,\n"," 'Loss/regularization_loss': 0.14825115,\n"," 'Loss/total_loss': 0.44147056,\n"," 'learning_rate': 0.07899711}\n","INFO:tensorflow:Step 4600 per-step time 1.618s\n","I0809 09:34:56.321114 140353392334720 model_lib_v2.py:700] Step 4600 per-step time 1.618s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2986282,\n"," 'Loss/localization_loss': 0.17579691,\n"," 'Loss/regularization_loss': 0.14803834,\n"," 'Loss/total_loss': 0.62246346,\n"," 'learning_rate': 0.078939244}\n","I0809 09:34:56.321478 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.2986282,\n"," 'Loss/localization_loss': 0.17579691,\n"," 'Loss/regularization_loss': 0.14803834,\n"," 'Loss/total_loss': 0.62246346,\n"," 'learning_rate': 0.078939244}\n","INFO:tensorflow:Step 4700 per-step time 1.624s\n","I0809 09:37:38.755544 140353392334720 model_lib_v2.py:700] Step 4700 per-step time 1.624s\n","INFO:tensorflow:{'Loss/classification_loss': 0.25737417,\n"," 'Loss/localization_loss': 0.10260997,\n"," 'Loss/regularization_loss': 0.14788401,\n"," 'Loss/total_loss': 0.5078682,\n"," 'learning_rate': 0.07887978}\n","I0809 09:37:38.755918 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.25737417,\n"," 'Loss/localization_loss': 0.10260997,\n"," 'Loss/regularization_loss': 0.14788401,\n"," 'Loss/total_loss': 0.5078682,\n"," 'learning_rate': 0.07887978}\n","INFO:tensorflow:Step 4800 per-step time 1.627s\n","I0809 09:40:21.406417 140353392334720 model_lib_v2.py:700] Step 4800 per-step time 1.627s\n","INFO:tensorflow:{'Loss/classification_loss': 0.097149774,\n"," 'Loss/localization_loss': 0.04072653,\n"," 'Loss/regularization_loss': 0.14767839,\n"," 'Loss/total_loss': 0.2855547,\n"," 'learning_rate': 0.07881871}\n","I0809 09:40:21.406813 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.097149774,\n"," 'Loss/localization_loss': 0.04072653,\n"," 'Loss/regularization_loss': 0.14767839,\n"," 'Loss/total_loss': 0.2855547,\n"," 'learning_rate': 0.07881871}\n","INFO:tensorflow:Step 4900 per-step time 1.632s\n","I0809 09:43:04.603369 140353392334720 model_lib_v2.py:700] Step 4900 per-step time 1.632s\n","INFO:tensorflow:{'Loss/classification_loss': 0.09204454,\n"," 'Loss/localization_loss': 0.03488008,\n"," 'Loss/regularization_loss': 0.14741324,\n"," 'Loss/total_loss': 0.27433786,\n"," 'learning_rate': 0.07875605}\n","I0809 09:43:04.603757 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.09204454,\n"," 'Loss/localization_loss': 0.03488008,\n"," 'Loss/regularization_loss': 0.14741324,\n"," 'Loss/total_loss': 0.27433786,\n"," 'learning_rate': 0.07875605}\n","INFO:tensorflow:Step 5000 per-step time 1.599s\n","I0809 09:45:44.463533 140353392334720 model_lib_v2.py:700] Step 5000 per-step time 1.599s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2516344,\n"," 'Loss/localization_loss': 0.07684276,\n"," 'Loss/regularization_loss': 0.14720458,\n"," 'Loss/total_loss': 0.47568172,\n"," 'learning_rate': 0.078691795}\n","I0809 09:45:44.463899 140353392334720 model_lib_v2.py:701] {'Loss/classification_loss': 0.2516344,\n"," 'Loss/localization_loss': 0.07684276,\n"," 'Loss/regularization_loss': 0.14720458,\n"," 'Loss/total_loss': 0.47568172,\n"," 'learning_rate': 0.078691795}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fKBOfK07W9JE","executionInfo":{"status":"ok","timestamp":1628503274473,"user_tz":-480,"elapsed":336,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["from google.colab import files"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGU2QDKtW_kZ"},"source":["files.download('/content/TF_Object_Detection/Tensorflow/workspace/models/my_ssd_mobnet/train') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QdCLsrCgaHSG"},"source":["# 7. Load Train Model From Checkpoint"]},{"cell_type":"code","metadata":{"id":"FAWnUnPlaHSG","executionInfo":{"status":"ok","timestamp":1628504294598,"user_tz":-480,"elapsed":659,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["import os\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"1CjAtq5JaHSH","executionInfo":{"status":"ok","timestamp":1628504296856,"user_tz":-480,"elapsed":8,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["# Load pipeline config and build a detection model\n","configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-6')).expect_partial()\n","\n","@tf.function\n","def detect_fn(image):\n","    image, shapes = detection_model.preprocess(image)\n","    prediction_dict = detection_model.predict(image, shapes)\n","    detections = detection_model.postprocess(prediction_dict, shapes)\n","    return detections"],"execution_count":76,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GjDqwjAIaHSH"},"source":["# 8. Detect in Real-Time"]},{"cell_type":"code","metadata":{"id":"PduRVA8XaHSH","executionInfo":{"status":"ok","timestamp":1628504431247,"user_tz":-480,"elapsed":352,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["import cv2 \n","import numpy as np\n","\n","from google.colab.patches import cv2_imshow"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwKPgBJoaHSI","executionInfo":{"status":"ok","timestamp":1628504303110,"user_tz":-480,"elapsed":541,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUdB-qwbaHSI","executionInfo":{"status":"ok","timestamp":1628505219082,"user_tz":-480,"elapsed":373,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["cap.release()"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0W3CCUnaHSI","executionInfo":{"status":"ok","timestamp":1628505659731,"user_tz":-480,"elapsed":343,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}}},"source":["# Setup capture\n","cap = cv2.VideoCapture(0)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"id":"baDK2F-AaHSI"},"source":["while True: \n","    ret, frame = cap.read()\n","    image_np = np.array(frame)\n","    \n","    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","    detections = detect_fn(input_tensor)\n","    \n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                  for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","                image_np_with_detections,\n","                detections['detection_boxes'],\n","                detections['detection_classes']+label_id_offset,\n","                detections['detection_scores'],\n","                category_index,\n","                use_normalized_coordinates=True,\n","                max_boxes_to_draw=5,\n","                min_score_thresh=.5,\n","                agnostic_mode=False)\n","\n","    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n","    \n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        cap.release()\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1EazJyBTU1IU4Dlps0Hr6XNsyerY7sMML"},"id":"TOs76KBAaHSK","executionInfo":{"status":"error","timestamp":1628505864454,"user_tz":-480,"elapsed":11123,"user":{"displayName":"Willy Liew","photoUrl":"","userId":"16501142898489481932"}},"outputId":"ee250cf1-e098-4690-87ba-84deda3fe038"},"source":["# Create a VideoCapture object and read from input file\n","# If the input is the camera, pass 0 instead of the video file name\n","cap = cv2.VideoCapture('/content/TF_Object_Detection/Tensorflow/workspace/Funny Cats and Dogs Compilation.mp4')\n","\n","# Check if camera opened successfully\n","if (cap.isOpened()== False): \n","  print(\"Error opening video stream or file\")\n","\n","# Read until video is completed\n","while(cap.isOpened()):\n","  # Capture frame-by-frame\n","  ret, frame = cap.read()\n","  image_np = np.array(frame)  # convert frame to numpy array\n","    \n","  input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","  detections = detect_fn(input_tensor)\n","  \n","  num_detections = int(detections.pop('num_detections'))  # return number of object detected\n","  detections = {key: value[0, :num_detections].numpy()    # preprocessing\n","                for key, value in detections.items()}     \n","  detections['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","  label_id_offset = 1\n","  image_np_with_detections = image_np.copy()\n","\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","              image_np_with_detections,\n","              detections['detection_boxes'],\n","              detections['detection_classes']+label_id_offset,\n","              detections['detection_scores'],\n","              category_index,\n","              use_normalized_coordinates=True,\n","              max_boxes_to_draw=5,\n","              min_score_thresh=.5,\n","              agnostic_mode=False)\n","\n","  # display the output on screen\n","  #cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n","  cv2_imshow(image_np_with_detections)\n","'''\n","  # Press Q on keyboard to  exit\n","  if cv2.waitKey(25) & 0xFF == ord('q'):\n","    break\n","'''\n","# When everything done, release the video capture object\n","cap.release()\n","\n","# Closes all the frames\n","cv2.destroyAllWindows()"],"execution_count":99,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"SPeqzZ1PaHSK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PWT_WSSaHSL"},"source":[""],"execution_count":null,"outputs":[]}]}